{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import arviz\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exprinment(is_cheater):\n",
    "    coin_result = flip_coin()\n",
    "    if (coin_result):\n",
    "        return is_cheater\n",
    "    else:\n",
    "        return flip_coin()\n",
    "\n",
    "def flip_coin():\n",
    "    result = False;\n",
    "    rand_value = random.random();\n",
    "    if (rand_value > 0.5):\n",
    "        result = True;\n",
    "    return result\n",
    "\n",
    "def compute_result_to_list(num_of_cheaters, num_of_people):\n",
    "    results = []\n",
    "    all_population = range(num_of_people)\n",
    "    cheaters_list = random.sample(all_population , k=num_of_cheaters)\n",
    "    for i in all_population:\n",
    "        result = False\n",
    "        if i in cheaters_list:\n",
    "            result = do_exprinment(True)\n",
    "        else :\n",
    "            result = do_exprinment(False)\n",
    "        if (result):\n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "            \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model = \"\"\"\n",
    "\n",
    "data {\n",
    "    int<lower=0> N; // number of people answered the survey\n",
    "    int<lower=0, upper = 1> y[N]; // boolean array of answers\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0, upper=1> theta; // the latent variable we want to infer\n",
    "    real<lower=-1, upper=1> coin_results[N]; // helper coin results buffer\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "    theta ~ beta(0.5, 0.5); // beta prior\n",
    "    for (i in 1:N){\n",
    "        coin_results[i] ~ normal(0 , 1);\n",
    "        if (coin_results[i] >= 0){\n",
    "            y[i] ~ bernoulli(theta);\n",
    "        }\n",
    "        else{\n",
    "            y[i] ~ bernoulli(0.5);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_model = \"\"\"\n",
    "\n",
    "data {\n",
    "    int<lower=0> N; // number of people answered the survey\n",
    "    int<lower=0, upper = 1> y[N]; // boolean array of answers\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0, upper=1> theta; // the latent variable we want to infer\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "    theta ~ beta(0.5, 0.5); // beta prior\n",
    "    for (i in 1:N){\n",
    "        target +=\n",
    "            log_mix(0.5, bernoulli_lpmf(y[i] | theta), bernoulli_lpmf(y[i] | 0.5));\n",
    "    }\n",
    "    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_10e97b055c992532f4f5189026ef2af5 NOW.\n"
     ]
    }
   ],
   "source": [
    "g_sm = pystan.StanModel(model_code=generative_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1faba59f95facd8bf45fceea85f1353e NOW.\n"
     ]
    }
   ],
   "source": [
    "m_sm = pystan.StanModel(model_code=mixture_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = compute_result_to_list(15 , 100);\n",
    "exp_1 = {\n",
    "    'N': len(y1),\n",
    "    'y': y1\n",
    "}\n",
    "\n",
    "\n",
    "y2 = compute_result_to_list(30 , 100);\n",
    "exp_2 = {\n",
    "    'N': len(y2),\n",
    "    'y': y2\n",
    "}\n",
    "\n",
    "\n",
    "y3 = compute_result_to_list(45 , 100);\n",
    "exp_3 = {\n",
    "    'N': len(y3),\n",
    "    'y': y3\n",
    "}\n",
    "\n",
    "\n",
    "y4 = compute_result_to_list(60, 100);\n",
    "exp_4 = {\n",
    "    'N': len(y4),\n",
    "    'y': y4\n",
    "}\n",
    "y5 = compute_result_to_list(75, 100);\n",
    "exp_5 = {\n",
    "    'N': len(y5),\n",
    "    'y': y5\n",
    "}\n",
    "\n",
    "\n",
    "y6 = compute_result_to_list(90, 100);\n",
    "exp_6 = {\n",
    "    'N': len(y6),\n",
    "    'y': y6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:2000 of 2000 iterations saturated the maximum tree depth of 11 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 11 to avoid saturation\n"
     ]
    }
   ],
   "source": [
    "g_fit = g_sm.sampling(data=exp_1, iter=1000, chains=4, control = {\"adapt_delta\" : 0.9 , 'max_treedepth': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_253b7b21ad7780ba0df8d0570d3407f2.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "                    mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "theta               0.15  5.1e-4   0.04   0.09   0.13   0.15   0.17   0.23   4771    1.0\n",
      "coin_results[1]     0.45  4.5e-3   0.28   0.02   0.21   0.43    0.7   0.97   3970    1.0\n",
      "coin_results[2]     0.46  4.4e-3   0.27   0.03   0.24   0.44   0.67   0.96   3674    1.0\n",
      "coin_results[3]     0.47  4.2e-3   0.28   0.03   0.22   0.45   0.69   0.96   4397    1.0\n",
      "coin_results[4]     0.46  4.4e-3   0.28   0.02   0.22   0.45   0.69   0.97   4114    1.0\n",
      "coin_results[5]     0.47  4.0e-3   0.29   0.02   0.22   0.45   0.71   0.97   5182    1.0\n",
      "coin_results[6]     0.46  4.5e-3   0.29   0.02   0.21   0.43    0.7   0.98   4161    1.0\n",
      "coin_results[7]     0.45  4.7e-3   0.28   0.03   0.21   0.44   0.68   0.95   3541    1.0\n",
      "coin_results[8]     0.46  4.8e-3   0.29   0.02   0.22   0.44   0.69   0.98   3567    1.0\n",
      "coin_results[9]     0.46  4.7e-3   0.29   0.02   0.22   0.44    0.7   0.97   3775    1.0\n",
      "coin_results[10]    0.46  5.1e-3   0.28   0.03   0.22   0.45    0.7   0.97   2941    1.0\n",
      "coin_results[11]    0.46  4.1e-3   0.28   0.02   0.21   0.44    0.7   0.97   4858    1.0\n",
      "coin_results[12]    0.46  4.2e-3   0.27   0.02   0.23   0.45   0.67   0.96   4103    1.0\n",
      "coin_results[13]    0.46  4.4e-3   0.27   0.03   0.24   0.44   0.68   0.95   3680    1.0\n",
      "coin_results[14]    0.47  4.3e-3   0.28   0.02   0.22   0.46    0.7   0.97   4429    1.0\n",
      "coin_results[15]    0.46  4.9e-3   0.29   0.01    0.2   0.45    0.7   0.97   3594    1.0\n",
      "coin_results[16]    0.46  4.1e-3   0.27   0.02   0.23   0.44   0.68   0.95   4332    1.0\n",
      "coin_results[17]    0.46  4.2e-3   0.28   0.02   0.23   0.45   0.69   0.96   4344    1.0\n",
      "coin_results[18]    0.46  4.6e-3   0.28   0.02   0.21   0.43   0.69   0.97   3799    1.0\n",
      "coin_results[19]    0.45  4.4e-3   0.28   0.02   0.21   0.43   0.68   0.95   3856    1.0\n",
      "coin_results[20]    0.46  4.1e-3   0.28   0.03   0.22   0.44   0.69   0.96   4627    1.0\n",
      "coin_results[21]    0.46  4.3e-3   0.28   0.02   0.23   0.44   0.68   0.97   4046    1.0\n",
      "coin_results[22]    0.47  4.7e-3   0.28   0.03   0.22   0.45    0.7   0.97   3614    1.0\n",
      "coin_results[23]    0.46  4.2e-3   0.28   0.03   0.22   0.45   0.68   0.95   4442    1.0\n",
      "coin_results[24]    0.47  4.4e-3   0.28   0.03   0.23   0.45   0.69   0.96   3902    1.0\n",
      "coin_results[25]    0.47  5.0e-3   0.28   0.02   0.22   0.45   0.71   0.96   3194    1.0\n",
      "coin_results[26]    0.46  4.1e-3   0.28   0.03   0.21   0.45   0.69   0.96   4694    1.0\n",
      "coin_results[27]    0.46  5.2e-3   0.28   0.02   0.22   0.45   0.69   0.97   3006    1.0\n",
      "coin_results[28]    0.46  5.1e-3   0.29   0.02   0.21   0.44    0.7   0.97   3184    1.0\n",
      "coin_results[29]    0.46  3.7e-3   0.29   0.02    0.2   0.44    0.7   0.97   6153    1.0\n",
      "coin_results[30]    0.46  4.8e-3   0.28   0.02   0.21   0.44    0.7   0.96   3546    1.0\n",
      "coin_results[31]    0.47  4.2e-3   0.29   0.02   0.22   0.45    0.7   0.97   4537    1.0\n",
      "coin_results[32]    0.47  4.4e-3   0.28   0.02   0.22   0.46    0.7   0.97   4137    1.0\n",
      "coin_results[33]    0.46  4.5e-3   0.28   0.02   0.21   0.44   0.68   0.96   3950    1.0\n",
      "coin_results[34]    0.46  3.9e-3   0.29   0.02   0.22   0.43    0.7   0.97   5341    1.0\n",
      "coin_results[35]    0.46  4.0e-3   0.28   0.03   0.21   0.45   0.71   0.96   4919    1.0\n",
      "coin_results[36]    0.46  4.4e-3   0.28   0.03   0.21   0.45   0.68   0.95   3985    1.0\n",
      "coin_results[37]    0.46  5.3e-3   0.29   0.02   0.21   0.44    0.7   0.97   2962    1.0\n",
      "coin_results[38]    0.46  4.5e-3   0.27   0.03   0.22   0.43   0.68   0.96   3643    1.0\n",
      "coin_results[39]    0.46  4.2e-3   0.28   0.03   0.21   0.43   0.69   0.96   4450    1.0\n",
      "coin_results[40]    0.47  4.1e-3   0.29   0.02   0.22   0.45   0.71   0.97   4796    1.0\n",
      "coin_results[41]    0.46  3.9e-3   0.27   0.03   0.23   0.44   0.67   0.96   4882    1.0\n",
      "coin_results[42]    0.46  4.6e-3   0.28   0.02   0.22   0.44   0.69   0.97   3828    1.0\n",
      "coin_results[43]    0.46  4.6e-3   0.29   0.03   0.21   0.43    0.7   0.96   3849    1.0\n",
      "coin_results[44]    0.45  4.4e-3   0.27   0.03   0.22   0.44   0.67   0.95   3815    1.0\n",
      "coin_results[45]    0.46  4.8e-3   0.29   0.01    0.2   0.44    0.7   0.97   3500    1.0\n",
      "coin_results[46]    0.47  4.0e-3   0.28   0.02   0.22   0.45    0.7   0.96   5041    1.0\n",
      "coin_results[47]    0.46  5.1e-3   0.28   0.02   0.21   0.44    0.7   0.97   3063    1.0\n",
      "coin_results[48]    0.45  4.0e-3   0.28   0.02   0.21   0.42   0.68   0.97   5009    1.0\n",
      "coin_results[49]    0.46  4.0e-3   0.28   0.02   0.21   0.43   0.69   0.97   5146    1.0\n",
      "coin_results[50]    0.46  4.3e-3   0.28   0.02   0.22   0.44   0.69   0.96   4170    1.0\n",
      "coin_results[51]    0.46  4.5e-3   0.29   0.02   0.21   0.43    0.7   0.96   4025    1.0\n",
      "coin_results[52]    0.47  4.8e-3   0.28   0.02   0.22   0.45    0.7   0.97   3391    1.0\n",
      "coin_results[53]    0.46  3.9e-3   0.27   0.03   0.23   0.44   0.68   0.96   4978    1.0\n",
      "coin_results[54]    0.46  4.6e-3   0.28   0.02   0.21   0.45    0.7   0.96   3829    1.0\n",
      "coin_results[55]    0.45  4.5e-3   0.28   0.02   0.21   0.42   0.68   0.97   3964    1.0\n",
      "coin_results[56]    0.46  4.6e-3   0.29   0.02    0.2   0.45    0.7   0.97   3976    1.0\n",
      "coin_results[57]    0.46  4.3e-3   0.28   0.02   0.21   0.43   0.69   0.96   4368    1.0\n",
      "coin_results[58]    0.46  4.6e-3   0.28   0.02   0.21   0.44   0.68   0.96   3736    1.0\n",
      "coin_results[59]    0.45  4.5e-3   0.28   0.02   0.21   0.44   0.69   0.95   3856    1.0\n",
      "coin_results[60]    0.45  4.6e-3   0.28   0.02   0.21   0.43   0.68   0.96   3654    1.0\n",
      "coin_results[61]    0.45  4.6e-3   0.28   0.02   0.19   0.43   0.69   0.97   3817    1.0\n",
      "coin_results[62]    0.46  4.0e-3   0.29   0.02   0.21   0.45   0.71   0.97   5279    1.0\n",
      "coin_results[63]    0.47  4.8e-3   0.29   0.02   0.22   0.45   0.72   0.97   3572    1.0\n",
      "coin_results[64]    0.46  4.1e-3   0.28   0.02   0.22   0.45    0.7   0.97   4809    1.0\n",
      "coin_results[65]    0.46  4.9e-3   0.28   0.03   0.21   0.45    0.7   0.96   3370    1.0\n",
      "coin_results[66]    0.46  4.9e-3   0.28   0.02   0.22   0.45   0.69   0.96   3319    1.0\n",
      "coin_results[67]    0.46  4.2e-3   0.28   0.03   0.21   0.43   0.68   0.96   4446    1.0\n",
      "coin_results[68]    0.46  4.5e-3   0.28   0.02   0.22   0.44   0.69   0.96   3849    1.0\n",
      "coin_results[69]    0.46  4.3e-3   0.28   0.02   0.23   0.45   0.69   0.96   4152    1.0\n",
      "coin_results[70]    0.46  4.2e-3   0.28   0.02   0.22   0.45   0.69   0.97   4443    1.0\n",
      "coin_results[71]    0.46  4.6e-3   0.28   0.02   0.22   0.44   0.68   0.97   3588    1.0\n",
      "coin_results[72]    0.45  4.3e-3   0.28   0.02   0.21   0.44   0.68   0.96   4326    1.0\n",
      "coin_results[73]    0.46  4.4e-3    0.3   0.02   0.19   0.44   0.71   0.97   4544    1.0\n",
      "coin_results[74]    0.45  4.1e-3   0.29   0.02    0.2   0.43   0.68   0.97   4790    1.0\n",
      "coin_results[75]    0.46  5.1e-3   0.29   0.02   0.21   0.43   0.71   0.97   3310    1.0\n",
      "coin_results[76]    0.46  4.8e-3   0.27   0.03   0.23   0.45   0.68   0.95   3154    1.0\n",
      "coin_results[77]    0.45  4.6e-3   0.28   0.02    0.2   0.43   0.69   0.96   3798    1.0\n",
      "coin_results[78]    0.46  4.2e-3   0.29   0.02    0.2   0.44    0.7   0.97   4630    1.0\n",
      "coin_results[79]    0.46  4.1e-3   0.28   0.03   0.22   0.44    0.7   0.95   4543    1.0\n",
      "coin_results[80]    0.46  3.7e-3   0.28   0.03   0.22   0.44    0.7   0.96   6007    1.0\n",
      "coin_results[81]    0.46  4.5e-3   0.28   0.02   0.22   0.44   0.69   0.96   3892    1.0\n",
      "coin_results[82]    0.46  4.2e-3   0.28   0.03   0.21   0.45   0.69   0.97   4477    1.0\n",
      "coin_results[83]    0.46  4.7e-3   0.29   0.02    0.2   0.44   0.71   0.97   3722    1.0\n",
      "coin_results[84]    0.45  3.9e-3   0.28   0.02   0.21   0.44   0.69   0.96   5394    1.0\n",
      "coin_results[85]    0.47  4.3e-3   0.29   0.02   0.22   0.45   0.71   0.97   4458    1.0\n",
      "coin_results[86]    0.45  4.2e-3   0.28   0.02   0.22   0.43   0.68   0.96   4446    1.0\n",
      "coin_results[87]    0.46  4.5e-3   0.28   0.02   0.22   0.44    0.7   0.96   3846    1.0\n",
      "coin_results[88]    0.46  3.9e-3   0.27   0.03   0.23   0.44   0.69   0.96   4943    1.0\n",
      "coin_results[89]    0.46  4.6e-3   0.29   0.02   0.21   0.45   0.71   0.98   4006    1.0\n",
      "coin_results[90]    0.47  4.6e-3   0.29   0.03   0.21   0.45   0.71   0.97   3839    1.0\n",
      "coin_results[91]    0.46  4.3e-3   0.29   0.02   0.21   0.43    0.7   0.97   4396    1.0\n",
      "coin_results[92]    0.46  4.3e-3   0.28   0.03   0.22   0.44   0.68   0.96   4113    1.0\n",
      "coin_results[93]    0.46  4.0e-3   0.27   0.03   0.23   0.44   0.68   0.96   4699    1.0\n",
      "coin_results[94]    0.45  3.9e-3   0.27   0.03   0.22   0.44   0.67   0.95   4859    1.0\n",
      "coin_results[95]    0.46  4.5e-3   0.28   0.03   0.21   0.45   0.71   0.96   4080    1.0\n",
      "coin_results[96]    0.46  4.1e-3   0.28   0.02   0.22   0.45   0.69   0.97   4751    1.0\n",
      "coin_results[97]    0.46  5.1e-3   0.28   0.02   0.23   0.44   0.69   0.97   3091    1.0\n",
      "coin_results[98]    0.46  4.7e-3   0.29   0.02   0.22   0.44    0.7   0.96   3744    1.0\n",
      "coin_results[99]    0.46  4.4e-3   0.28   0.02    0.2   0.44    0.7   0.97   4151    1.0\n",
      "coin_results[100]   0.46  4.3e-3   0.28   0.02   0.21   0.44   0.69   0.97   4381    1.0\n",
      "lp__              -255.8    0.33   8.35 -273.6 -261.4 -255.4 -249.8 -240.9    626    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Fri Dec 27 21:30:37 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(g_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1faba59f95facd8bf45fceea85f1353e.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "        mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "theta   0.34  4.2e-3    0.1   0.14   0.26   0.34    0.4   0.54    583   1.01\n",
      "lp__  -69.36    0.04   0.82 -71.66 -69.54 -69.05 -68.83 -68.77    386   1.02\n",
      "\n",
      "Samples were drawn using NUTS at Sat Dec 28 15:31:41 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "m_fit = m_sm.sampling(data=exp_1, iter=1000, chains=4, control = {\"adapt_delta\" : 0.9})\n",
    "\n",
    "print(m_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1faba59f95facd8bf45fceea85f1353e.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "        mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "theta   0.25  3.8e-3    0.1   0.08   0.19   0.25   0.32   0.44    627    1.0\n",
      "lp__  -67.78    0.03   0.75 -69.95 -67.97 -67.49 -67.28 -67.22    506    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Dec 28 15:27:45 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "m_fit2 = m_sm.sampling(data=exp_2, iter=1000, chains=4, control = {\"adapt_delta\" : 0.9})\n",
    "\n",
    "print(m_fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1faba59f95facd8bf45fceea85f1353e.\n",
      "7 chains, each with iter=5000; warmup=2500; thin=1; \n",
      "post-warmup draws per chain=2500, total post-warmup draws=17500.\n",
      "\n",
      "        mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "theta   0.21  1.4e-3    0.1   0.02   0.14    0.2   0.27    0.4   4612    1.0\n",
      "lp__  -66.89    0.02   0.97 -69.81 -67.12 -66.51 -66.28 -66.21   2564    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Dec 28 15:32:27 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "m_fit3 = m_sm.sampling(data=exp_3, iter=5000, chains=7)\n",
    "\n",
    "print(m_fit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1faba59f95facd8bf45fceea85f1353e.\n",
      "4 chains, each with iter=5000; warmup=2500; thin=1; \n",
      "post-warmup draws per chain=2500, total post-warmup draws=10000.\n",
      "\n",
      "        mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "theta   0.71  2.0e-3    0.1   0.51   0.64   0.71   0.78   0.91   2668    1.0\n",
      "lp__  -68.69    0.02    0.9 -71.31 -68.87 -68.35 -68.14 -68.08   1742    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Dec 28 15:30:06 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "m_fit4 = m_sm.sampling(data=exp_4, iter=5000, chains=4, control = {\"adapt_delta\" : 0.9})\n",
    "print(m_fit4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1faba59f95facd8bf45fceea85f1353e.\n",
      "4 chains, each with iter=5000; warmup=2500; thin=1; \n",
      "post-warmup draws per chain=2500, total post-warmup draws=10000.\n",
      "\n",
      "        mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "theta   0.82  2.1e-3    0.1   0.62   0.75   0.82   0.89   0.99   2133    1.0\n",
      "lp__  -66.37    0.03   1.02 -69.42 -66.59 -65.96 -65.71 -65.65   1201    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Dec 28 15:30:59 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "m_fit5 = m_sm.sampling(data=exp_5, iter=5000, chains=4, control = {\"adapt_delta\" : 0.9})\n",
    "print(m_fit5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
