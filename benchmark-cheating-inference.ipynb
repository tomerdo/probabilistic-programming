{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import arviz\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exprinment(is_cheater):\n",
    "    coin_result = flip_coin()\n",
    "    if (coin_result):\n",
    "        return is_cheater\n",
    "    else:\n",
    "        return flip_coin()\n",
    "\n",
    "def flip_coin():\n",
    "    result = False;\n",
    "    rand_value = random();\n",
    "    if (rand_value > 0.5):\n",
    "        result = True;\n",
    "    return result\n",
    "\n",
    "def compute_result_to_list(num_of_cheaters, num_of_people):\n",
    "    results = []\n",
    "    all_population = range(num_of_people)\n",
    "    cheaters_list = random.sample(all_population , k=num_of_cheaters)\n",
    "    for i in all_population:\n",
    "        if i in cheaters_list:\n",
    "            results.append(1);\n",
    "        else:\n",
    "            results.append(0)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model = \"\"\"\n",
    "\n",
    "data {\n",
    "    int<lower=0> N; // number of people answered the survey\n",
    "    int<lower=0, upper = 1> y[N]; // boolean array of answers\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0, upper=1> theta; // the latent variable we want to infer\n",
    "    real<lower=0, upper=1> coin_results[N]; // helper coin results buffer\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "    theta ~ beta(0.5, 0.5); // beta prior\n",
    "    for (i in 1:N){\n",
    "        coin_results[i] ~ normal(0 , 1);\n",
    "        if (coin_results[i] >= 0){\n",
    "            y[i] ~ bernoulli(theta);\n",
    "        }\n",
    "        else{\n",
    "            y[i] ~ bernoulli(0.5);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_model = \"\"\"\n",
    "\n",
    "data {\n",
    "    int<lower=0> N; // number of people answered the survey\n",
    "    int<lower=0, upper = 1> y[N]; // boolean array of answers\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0, upper=1> theta; // the latent variable we want to infer\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "    theta ~ beta(0.5, 0.5); // beta prior\n",
    "    for (i in 1:N){\n",
    "        target +=\n",
    "            log_mix(0.5, bernoulli_lpmf(y[i] | theta), bernoulli_lpmf(y[i] | 0.5));\n",
    "    }\n",
    "    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_253b7b21ad7780ba0df8d0570d3407f2 NOW.\n"
     ]
    }
   ],
   "source": [
    "g_sm = pystan.StanModel(model_code=generative_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1faba59f95facd8bf45fceea85f1353e NOW.\n"
     ]
    }
   ],
   "source": [
    "m_sm = pystan.StanModel(model_code=mixture_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = compute_result_to_list(15 , 100);\n",
    "exp_1 = {\n",
    "    'N': len(y1),\n",
    "    'y': y1\n",
    "}\n",
    "\n",
    "\n",
    "y2 = compute_result_to_list(30 , 100);\n",
    "exp_2 = {\n",
    "    'N': len(y2),\n",
    "    'y': y2\n",
    "}\n",
    "\n",
    "\n",
    "y3 = compute_result_to_list(45 , 100);\n",
    "exp_3 = {\n",
    "    'N': len(y3),\n",
    "    'y': y3\n",
    "}\n",
    "\n",
    "\n",
    "y4 = compute_result_to_list(60, 100);\n",
    "exp_4 = {\n",
    "    'N': len(y4),\n",
    "    'y': y4\n",
    "}\n",
    "y5 = compute_result_to_list(75, 100);\n",
    "exp_5 = {\n",
    "    'N': len(y5),\n",
    "    'y': y5\n",
    "}\n",
    "\n",
    "\n",
    "y6 = compute_result_to_list(90, 100);\n",
    "exp_6 = {\n",
    "    'N': len(y6),\n",
    "    'y': y6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fit = g_sm.sampling(data=exp_1, iter=1000, chains=4, control = {\"adapt_delta\" : 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
